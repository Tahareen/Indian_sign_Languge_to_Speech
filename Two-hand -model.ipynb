{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":119281,"status":"ok","timestamp":1744560031149,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"PhI33bJc3vuX","outputId":"b18067b7-a875-429a-aebc-03f9ce8ccaff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n","Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-25.0.1\n","Collecting mediapipe-model-maker\n","  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (1.4.0)\n","Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n","  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.0.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.11.0.86)\n","Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)\n","  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting tensorflow-addons (from mediapipe-model-maker)\n","  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.9.8)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.16.1)\n","Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.18.1)\n","Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.10.0)\n","Collecting numpy (from mediapipe-model-maker)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.11.0.86)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.13.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n","  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (24.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.13.1)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n","  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.71.0)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.9)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.12)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.1.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.164.0)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.2)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.11.0.86)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.8)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n","Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.14.1)\n","Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow-text (from mediapipe-model-maker)\n","  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.18.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.7.1)\n","Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.12.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (18.1.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)\n","Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.17.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.67.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.3.2)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.21.0)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.38.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.24.2)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.1.31)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.4.1)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.3.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)\n","INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n","Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n","  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n","  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n","  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n","INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n","  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n","  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n","  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.2.3)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.2)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9)\n","Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n","Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.3.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.1)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.69.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.2)\n","Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n","Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n","Downloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=442886d344a193ba5f7b9cc73a1c561f103d10e05d1f2f6d6f44c7bc47ba8917\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n","Successfully built seqeval\n","Installing collected packages: wrapt, typeguard, tensorflow-estimator, protobuf, portalocker, numpy, keras, colorama, tensorflow-addons, sounddevice, sacrebleu, ml-dtypes, tensorflow-model-optimization, jaxlib, tensorboard, seqeval, jax, tensorflow, mediapipe, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.2\n","    Uninstalling wrapt-1.17.2:\n","      Successfully uninstalled wrapt-1.17.2\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.4.2\n","    Uninstalling typeguard-4.4.2:\n","      Successfully uninstalled typeguard-4.4.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.8.0\n","    Uninstalling keras-3.8.0:\n","      Successfully uninstalled keras-3.8.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: jaxlib\n","    Found existing installation: jaxlib 0.5.1\n","    Uninstalling jaxlib-0.5.1:\n","      Successfully uninstalled jaxlib-0.5.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","  Attempting uninstall: jax\n","    Found existing installation: jax 0.5.2\n","    Uninstalling jax-0.5.2:\n","      Successfully uninstalled jax-0.5.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.18.0\n","    Uninstalling tensorflow-2.18.0:\n","      Successfully uninstalled tensorflow-2.18.0\n","  Attempting uninstall: tf-keras\n","    Found existing installation: tf_keras 2.18.0\n","    Uninstalling tf_keras-2.18.0:\n","      Successfully uninstalled tf_keras-2.18.0\n","  Attempting uninstall: tensorflow-text\n","    Found existing installation: tensorflow-text 2.18.1\n","    Uninstalling tensorflow-text-2.18.1:\n","      Successfully uninstalled tensorflow-text-2.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n","flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.34 which is incompatible.\n","inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n","dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n","orbax-checkpoint 0.11.10 requires jax>=0.5.0, but you have jax 0.4.34 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed colorama-0.4.6 jax-0.4.34 jaxlib-0.4.34 keras-2.15.0 mediapipe-0.10.21 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 numpy-1.26.4 portalocker-3.1.1 protobuf-4.25.6 sacrebleu-2.5.1 seqeval-1.2.2 sounddevice-0.5.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n"]}],"source":["!pip install --upgrade pip\n","!pip install mediapipe-model-maker"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3778,"status":"ok","timestamp":1744911461166,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"YKSXzasY5oBN","outputId":"8bb66fae-fbae-4395-cf82-5d2082925fe2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n","Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n","Requirement already satisfied: tf-keras==2.15.1 in /usr/local/lib/python3.11/dist-packages (2.15.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.13.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.71.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n"]}],"source":["!pip install numpy==1.24.4 tensorflow==2.15.0 tf-keras==2.15.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":41564,"status":"ok","timestamp":1744911507848,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"3E4N0LvT6Deb","outputId":"6987fd2f-e5a2-4c97-bcc5-d8e882d92bff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Collecting tensorflow-model-optimization\n","  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n","Collecting mediapipe-model-maker\n","  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (2.18.1)\n","Requirement already satisfied: tensorflow-decision-forests in /usr/local/lib/python3.11/dist-packages (1.11.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.24.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n","Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.11.0.86)\n","Requirement already satisfied: tensorflow<2.16,>=2.10 in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.15.0)\n","Collecting tensorflow-addons (from mediapipe-model-maker)\n","  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.9.8)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.16.1)\n","Collecting tensorflow-model-optimization\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n","Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-text\n","  Downloading tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","  Downloading tensorflow_text-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","  Downloading tensorflow_text-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","  Downloading tensorflow_text-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests) (2.2.2)\n","INFO: pip is looking at multiple versions of tensorflow-decision-forests to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-decision-forests\n","  Downloading tensorflow_decision_forests-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n","  Downloading tensorflow_decision_forests-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n","  Downloading tensorflow_decision_forests-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","  Downloading tensorflow_decision_forests-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","  Downloading tensorflow_decision_forests-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","  Downloading tensorflow_decision_forests-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","  Downloading tensorflow_decision_forests-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests) (0.45.1)\n","Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests) (3.1.1)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.13.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (24.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.13.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.71.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.15.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.12)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.1.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.164.0)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.2)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.11.0.86)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.8)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n","Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.14.1)\n","Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests) (2025.2)\n","INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n","  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n","INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Collecting jax (from mediapipe)\n","  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib (from mediapipe)\n","  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.7.1)\n","Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.12.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (18.1.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)\n","Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.17.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.67.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.3.2)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.21.0)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.38.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.24.2)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.1.31)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.4.1)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.3.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.2)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9)\n","Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n","Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.3.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.1)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.69.2)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.2)\n","Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_decision_forests-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=dce9eb32b71efd9b16050e749ba62dd686515d7892da2f47b086e0771a0e5a6e\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n","Successfully built seqeval\n","Installing collected packages: typeguard, portalocker, colorama, tensorflow-model-optimization, tensorflow-addons, sounddevice, sacrebleu, jaxlib, seqeval, jax, mediapipe, tensorflow-decision-forests, tensorflow-text, tf-models-official, mediapipe-model-maker\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.4.2\n","    Uninstalling typeguard-4.4.2:\n","      Successfully uninstalled typeguard-4.4.2\n","  Attempting uninstall: jaxlib\n","    Found existing installation: jaxlib 0.5.1\n","    Uninstalling jaxlib-0.5.1:\n","      Successfully uninstalled jaxlib-0.5.1\n","  Attempting uninstall: jax\n","    Found existing installation: jax 0.5.2\n","    Uninstalling jax-0.5.2:\n","      Successfully uninstalled jax-0.5.2\n","  Attempting uninstall: tensorflow-decision-forests\n","    Found existing installation: tensorflow_decision_forests 1.11.0\n","    Uninstalling tensorflow_decision_forests-1.11.0:\n","      Successfully uninstalled tensorflow_decision_forests-1.11.0\n","  Attempting uninstall: tensorflow-text\n","    Found existing installation: tensorflow-text 2.18.1\n","    Uninstalling tensorflow-text-2.18.1:\n","      Successfully uninstalled tensorflow-text-2.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n","inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n","flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.34 which is incompatible.\n","orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.34 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed colorama-0.4.6 jax-0.4.34 jaxlib-0.4.34 mediapipe-0.10.21 mediapipe-model-maker-0.2.1.4 portalocker-3.1.1 sacrebleu-2.5.1 seqeval-1.2.2 sounddevice-0.5.1 tensorflow-addons-0.23.0 tensorflow-decision-forests-1.8.1 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-models-official-2.15.0 typeguard-2.13.3\n"]}],"source":["!pip install mediapipe tensorflow-model-optimization mediapipe-model-maker tensorflow-text tensorflow-decision-forests\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9480,"status":"ok","timestamp":1744911532598,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"0SkJ0SSU4bXW","outputId":"575194cf-8e07-4330-8b29-5634a63021f1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["from google.colab import files\n","import os\n","\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","assert tf.__version__.startswith('2')\n","\n","from mediapipe_model_maker import gesture_recognizer\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","import zipfile\n","\n","# Step 1: Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Unzip your dataset directly to /content/\n","# zip_path = '/content/drive/My Drive/two-hand_extra.zip'  # <-- Change this!\n","# extract_path = '/content'  # unzip directly to /content\n","\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(extract_path)\n","\n","# Step 3: Set the path to your dataset folder\n","dataset_path = '/content/2-hand-data'\n","\n","# for f in os.listdir(dataset_path):\n","#     full_path = os.path.join(dataset_path, f)\n","#     print(f\"{f} - Is directory? {os.path.isdir(full_path)}\")\n","\n","# Step 4: List all alphabet folders\n","alphabet_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n","\n","print(f\"\\nTotal number of alphabet folders: {len(alphabet_folders)}\\n\")\n","\n","# Step 5: Count images in each folder\n","for folder in sorted(alphabet_folders):\n","    folder_path = os.path.join(dataset_path, folder)\n","    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","    print(f\"📁 Folder: {folder} - 🖼️ {len(image_files)} images\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMHdyh3SbleJ","executionInfo":{"status":"ok","timestamp":1744911573632,"user_tz":-330,"elapsed":3092,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"694f9dfb-4920-4559-fbcc-080edb732082"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Total number of alphabet folders: 21\n","\n","📁 Folder: A - 🖼️ 2000 images\n","📁 Folder: B - 🖼️ 2000 images\n","📁 Folder: D - 🖼️ 2000 images\n","📁 Folder: E - 🖼️ 2000 images\n","📁 Folder: F - 🖼️ 2000 images\n","📁 Folder: G - 🖼️ 2000 images\n","📁 Folder: H - 🖼️ 2000 images\n","📁 Folder: J - 🖼️ 2000 images\n","📁 Folder: K - 🖼️ 2000 images\n","📁 Folder: M - 🖼️ 2000 images\n","📁 Folder: N - 🖼️ 2000 images\n","📁 Folder: P - 🖼️ 2000 images\n","📁 Folder: Q - 🖼️ 2000 images\n","📁 Folder: R - 🖼️ 2000 images\n","📁 Folder: S - 🖼️ 2000 images\n","📁 Folder: T - 🖼️ 2000 images\n","📁 Folder: W - 🖼️ 2000 images\n","📁 Folder: X - 🖼️ 2000 images\n","📁 Folder: Y - 🖼️ 2000 images\n","📁 Folder: Z - 🖼️ 2096 images\n","📁 Folder: none - 🖼️ 2000 images\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Paths to your datasets\n","dataset1_path = '/content/datanew'   # Update this to your actual dataset 1 path\n","dataset2_path = '/content/two-hand'   # Update this to your actual dataset 2 path\n","output_path = '/content/2-hand-data'\n","\n","# Create new folder\n","os.makedirs(output_path, exist_ok=True)\n","\n","# Get list of subfolders (alphabet labels) from dataset 1\n","folder_names = [f for f in os.listdir(dataset1_path) if os.path.isdir(os.path.join(dataset1_path, f))]\n","\n","# Loop through each subfolder name\n","for folder in sorted(folder_names):\n","    folder1 = os.path.join(dataset1_path, folder)\n","    folder2 = os.path.join(dataset2_path, folder)\n","    new_folder = os.path.join(output_path, folder)\n","\n","    # Create the new subfolder\n","    os.makedirs(new_folder, exist_ok=True)\n","\n","    count = 0\n","\n","    # Copy images from dataset1\n","    if os.path.exists(folder1):\n","        for file in os.listdir(folder1):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                src = os.path.join(folder1, file)\n","                dst = os.path.join(new_folder, f\"ds1_{file}\")\n","                shutil.copy(src, dst)\n","                count += 1\n","\n","    # Copy images from dataset2\n","    if os.path.exists(folder2):\n","        for file in os.listdir(folder2):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                src = os.path.join(folder2, file)\n","                dst = os.path.join(new_folder, f\"ds2_{file}\")\n","                shutil.copy(src, dst)\n","                count += 1\n","\n","    print(f\"✅ Created folder: {folder} - 📸 Total images copied: {count}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmIMXgHKlLdi","executionInfo":{"status":"ok","timestamp":1744909866483,"user_tz":-330,"elapsed":34626,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"af3e5c1d-28dc-4d3f-a09b-63e59e80a1c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Created folder: A - 📸 Total images copied: 1638\n","✅ Created folder: B - 📸 Total images copied: 1788\n","✅ Created folder: D - 📸 Total images copied: 1835\n","✅ Created folder: E - 📸 Total images copied: 1818\n","✅ Created folder: F - 📸 Total images copied: 1996\n","✅ Created folder: G - 📸 Total images copied: 1786\n","✅ Created folder: H - 📸 Total images copied: 1828\n","✅ Created folder: J - 📸 Total images copied: 1732\n","✅ Created folder: K - 📸 Total images copied: 1877\n","✅ Created folder: M - 📸 Total images copied: 1832\n","✅ Created folder: N - 📸 Total images copied: 1803\n","✅ Created folder: P - 📸 Total images copied: 1814\n","✅ Created folder: Q - 📸 Total images copied: 1874\n","✅ Created folder: R - 📸 Total images copied: 1912\n","✅ Created folder: S - 📸 Total images copied: 1956\n","✅ Created folder: T - 📸 Total images copied: 1804\n","✅ Created folder: W - 📸 Total images copied: 1914\n","✅ Created folder: X - 📸 Total images copied: 1875\n","✅ Created folder: Y - 📸 Total images copied: 1401\n","✅ Created folder: Z - 📸 Total images copied: 2096\n","✅ Created folder: none - 📸 Total images copied: 1086\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","import shutil\n","\n","# 1. Set the folder you want to download\n","folder_path = \"/content/2-hand-data\"\n","\n","# 2. Zip the folder\n","shutil.make_archive(\"2-hand-data\", 'zip', folder_path)\n","\n","# 3. Download the zip file to your local PC\n","files.download(\"2-hand-data.zip\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"rQmO-qnzxPpr","executionInfo":{"status":"ok","timestamp":1744910572258,"user_tz":-330,"elapsed":79395,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"69776ae9-dbde-4ed7-b3b8-f5ae8c483016"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a733e35a-cada-40d8-aa87-342c0c0d51db\", \"2-hand-data.zip\", 1360913306)"]},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","import shutil\n","import os\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Set source and destination paths\n","source_folder = '/content/2-hand-data'  # 🔁 Replace with your folder in /content\n","destination_folder = '/content/drive/MyDrive/2-hand-data'  # 🔁 Change destination name if needed\n","\n","# 3. Copy the folder to Google Drive\n","shutil.copytree(source_folder, destination_folder)\n","\n","print(f\"✅ Folder '{source_folder}' successfully copied to Drive at '{destination_folder}'\")\n"],"metadata":{"id":"q-WhofSebwnb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744910212105,"user_tz":-330,"elapsed":29272,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"ef4c6ba5-d617-4c4f-cac2-0ecd10eeaa9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Folder '/content/2-hand-data' successfully copied to Drive at '/content/drive/MyDrive/2-hand-data'\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Paths in Google Colab (adjust as needed)\n","dataset1_path = '/content/two-hand'\n","dataset2_path = '/content/datanew'\n","merged_dataset_path = '/content/merged_dataset_new'\n","\n","# Create merged dataset folder\n","os.makedirs(merged_dataset_path, exist_ok=True)\n","\n","# Get all class folders (assuming same structure)\n","class_folders = os.listdir(dataset1_path)\n","\n","for class_name in class_folders:\n","    class_path1 = os.path.join(dataset1_path, class_name)\n","    class_path2 = os.path.join(dataset2_path, class_name)\n","    merged_class_path = os.path.join(merged_dataset_path, class_name)\n","\n","    # Create class folder in merged dataset\n","    os.makedirs(merged_class_path, exist_ok=True)\n","\n","    # Copy from dataset1\n","    if os.path.isdir(class_path1):\n","        for file in os.listdir(class_path1):\n","            src = os.path.join(class_path1, file)\n","            dst = os.path.join(merged_class_path, f\"ds1_{file}\")\n","            shutil.copy2(src, dst)\n","\n","    # Copy from dataset2\n","    if os.path.isdir(class_path2):\n","        for file in os.listdir(class_path2):\n","            src = os.path.join(class_path2, file)\n","            dst = os.path.join(merged_class_path, f\"ds2_{file}\")\n","            shutil.copy2(src, dst)\n","\n","print(\"✅ Merge complete! Merged dataset is at:\", merged_dataset_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0D_6kAgHaUkf","executionInfo":{"status":"ok","timestamp":1744907065955,"user_tz":-330,"elapsed":37673,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"ed54f571-cf97-4f14-a48a-0cda967e3844"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Merge complete! Merged dataset is at: /content/merged_dataset_new\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Paths in Google Colab (adjust as needed)\n","dataset1_path = '/content/dataset1'\n","dataset2_path = '/content/dataset2'\n","merged_dataset_path = '/content/merged_dataset'\n","\n","# Create merged dataset folder\n","os.makedirs(merged_dataset_path, exist_ok=True)\n","\n","# Get all class folders (assuming same structure)\n","class_folders = os.listdir(dataset1_path)\n","\n","for class_name in class_folders:\n","    class_path1 = os.path.join(dataset1_path, class_name)\n","    class_path2 = os.path.join(dataset2_path, class_name)\n","    merged_class_path = os.path.join(merged_dataset_path, class_name)\n","\n","    # Create class folder in merged dataset\n","    os.makedirs(merged_class_path, exist_ok=True)\n","\n","    # Copy from dataset1\n","    if os.path.isdir(class_path1):\n","        for file in os.listdir(class_path1):\n","            src = os.path.join(class_path1, file)\n","            dst = os.path.join(merged_class_path, f\"ds1_{file}\")\n","            shutil.copy2(src, dst)\n","\n","    # Copy from dataset2\n","    if os.path.isdir(class_path2):\n","        for file in os.listdir(class_path2):\n","            src = os.path.join(class_path2, file)\n","            dst = os.path.join(merged_class_path, f\"ds2_{file}\")\n","            shutil.copy2(src, dst)\n","\n","print(\"✅ Merge complete! Merged dataset is at:\", merged_dataset_path)\n"],"metadata":{"id":"jvMU0HEpaLtg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import albumentations as A\n","from tqdm import tqdm\n","import random\n","\n","# Path to your dataset\n","dataset_path = '/content/2-hand-data'\n","\n","# Target total images per folder\n","target_image_count = 2000\n","\n","# Augmentation pipeline (unchanged)\n","augment = A.Compose([\n","    A.Rotate(limit=15, p=0.8),\n","    A.RandomBrightnessContrast(p=0.8),\n","    A.RandomScale(scale_limit=0.1, p=0.8),\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.0, rotate_limit=0, p=0.7),\n","    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","    A.MotionBlur(blur_limit=3, p=0.2)\n","])\n","\n","def augment_and_save_images(class_folder):\n","    # All image files\n","    images = [img for img in os.listdir(class_folder) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n","    current_count = len(images)\n","\n","    # How many images we need to add\n","    remaining_to_add = target_image_count - current_count\n","    if remaining_to_add <= 0:\n","        print(f\"✅ Skipping {os.path.basename(class_folder)} (already has {current_count} images)\")\n","        return\n","\n","    # Try to select 'Screenshot' images first\n","    screenshot_images = [img for img in images if img.startswith(\"Screenshot\")]\n","    selected_images = screenshot_images if screenshot_images else images\n","    image_paths = [os.path.join(class_folder, img) for img in selected_images]\n","\n","    if len(image_paths) == 0:\n","        print(f\"⚠️ No valid images found in {class_folder}\")\n","        return\n","\n","    for i in tqdm(range(remaining_to_add), desc=f\"Augmenting {os.path.basename(class_folder)}\"):\n","        img_path = random.choice(image_paths)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        augmented = augment(image=image)['image']\n","        output_image = cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)\n","\n","        out_path = os.path.join(class_folder, f\"aug_{i + current_count}.jpg\")\n","        cv2.imwrite(out_path, output_image)\n","\n","# Loop through each class folder\n","for class_name in os.listdir(dataset_path):\n","    class_path = os.path.join(dataset_path, class_name)\n","    if os.path.isdir(class_path):\n","        augment_and_save_images(class_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSmIOBT3a1v1","executionInfo":{"status":"ok","timestamp":1744909955135,"user_tz":-330,"elapsed":35625,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"c0776fda-3c86-4188-95ab-9615f35afa93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-54-9b8f1fed1425>:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","Augmenting W: 100%|██████████| 86/86 [00:01<00:00, 69.56it/s]\n","Augmenting J: 100%|██████████| 268/268 [00:02<00:00, 108.86it/s]\n","Augmenting Q: 100%|██████████| 126/126 [00:01<00:00, 68.99it/s]\n","Augmenting Y: 100%|██████████| 599/599 [00:01<00:00, 493.18it/s]\n","Augmenting N: 100%|██████████| 197/197 [00:02<00:00, 84.91it/s]\n","Augmenting X: 100%|██████████| 125/125 [00:00<00:00, 133.95it/s]\n","Augmenting R: 100%|██████████| 88/88 [00:00<00:00, 134.85it/s]\n","Augmenting M: 100%|██████████| 168/168 [00:02<00:00, 66.49it/s]\n","Augmenting E: 100%|██████████| 182/182 [00:02<00:00, 73.68it/s] \n","Augmenting T: 100%|██████████| 196/196 [00:01<00:00, 159.43it/s]\n","Augmenting P: 100%|██████████| 186/186 [00:01<00:00, 119.24it/s]\n","Augmenting none: 100%|██████████| 914/914 [00:06<00:00, 137.13it/s]\n","Augmenting D: 100%|██████████| 165/165 [00:01<00:00, 83.44it/s]\n","Augmenting F: 100%|██████████| 4/4 [00:00<00:00, 170.96it/s]\n","Augmenting K: 100%|██████████| 123/123 [00:01<00:00, 110.70it/s]\n","Augmenting A: 100%|██████████| 362/362 [00:02<00:00, 165.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Skipping Z (already has 2096 images)\n"]},{"output_type":"stream","name":"stderr","text":["Augmenting H: 100%|██████████| 172/172 [00:01<00:00, 98.79it/s]\n","Augmenting S: 100%|██████████| 44/44 [00:00<00:00, 119.41it/s]\n","Augmenting G: 100%|██████████| 214/214 [00:01<00:00, 142.11it/s]\n","Augmenting B: 100%|██████████| 212/212 [00:01<00:00, 128.99it/s]\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import albumentations as A\n","from tqdm import tqdm\n","import random\n","\n","# Path to your dataset\n","dataset_path = '/content/two-hand'\n","\n","# How many augmented images to add per folder\n","augmented_count = 200\n","\n","# Augmentation pipeline (unchanged)\n","augment = A.Compose([\n","    A.Rotate(limit=15, p=0.8),\n","    A.RandomBrightnessContrast(p=0.8),\n","    A.RandomScale(scale_limit=0.1, p=0.8),\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.0, rotate_limit=0, p=0.7),\n","    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","    A.MotionBlur(blur_limit=3, p=0.2)\n","])\n","\n","def augment_and_save_images(class_folder):\n","    images = [img for img in os.listdir(class_folder) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n","    screenshot_images = [img for img in images if img.startswith(\"Screenshot\")]\n","\n","    # Fallback to all images if no 'Screenshot' images found\n","    selected_images = screenshot_images if screenshot_images else images\n","    image_paths = [os.path.join(class_folder, img) for img in selected_images]\n","\n","    if len(image_paths) == 0:\n","        return\n","\n","    for i in tqdm(range(augmented_count), desc=f\"Augmenting {os.path.basename(class_folder)}\"):\n","        img_path = random.choice(image_paths)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        augmented = augment(image=image)['image']\n","        output_image = cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)\n","\n","        out_path = os.path.join(class_folder, f\"aug_{i}.jpg\")\n","        cv2.imwrite(out_path, output_image)\n","\n","# Loop through each class folder\n","for class_name in os.listdir(dataset_path):\n","    class_path = os.path.join(dataset_path, class_name)\n","    if os.path.isdir(class_path):\n","        augment_and_save_images(class_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8VxPiWqZaqJ","executionInfo":{"status":"ok","timestamp":1744904317807,"user_tz":-330,"elapsed":38115,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"af05de02-ab7e-4dbd-e8b0-80a9943e7c94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n","<ipython-input-2-d998900008d8>:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","Augmenting W: 100%|██████████| 200/200 [00:00<00:00, 459.90it/s]\n","Augmenting J: 100%|██████████| 200/200 [00:00<00:00, 416.69it/s]\n","Augmenting Q: 100%|██████████| 200/200 [00:06<00:00, 29.79it/s]\n","Augmenting Y: 100%|██████████| 200/200 [00:00<00:00, 417.81it/s]\n","Augmenting N: 100%|██████████| 200/200 [00:05<00:00, 38.39it/s]\n","Augmenting X: 100%|██████████| 200/200 [00:00<00:00, 355.65it/s]\n","Augmenting R: 100%|██████████| 200/200 [00:00<00:00, 425.43it/s]\n","Augmenting M: 100%|██████████| 200/200 [00:06<00:00, 29.82it/s]\n","Augmenting E: 100%|██████████| 200/200 [00:00<00:00, 352.85it/s]\n","Augmenting T: 100%|██████████| 200/200 [00:00<00:00, 601.94it/s]\n","Augmenting P: 100%|██████████| 200/200 [00:00<00:00, 441.64it/s]\n","Augmenting D: 100%|██████████| 200/200 [00:00<00:00, 292.79it/s]\n","Augmenting F: 100%|██████████| 200/200 [00:00<00:00, 684.22it/s]\n","Augmenting K: 100%|██████████| 200/200 [00:00<00:00, 406.55it/s]\n","Augmenting A: 100%|██████████| 200/200 [00:00<00:00, 560.48it/s]\n","Augmenting Z: 100%|██████████| 200/200 [00:05<00:00, 39.66it/s]\n","Augmenting H: 100%|██████████| 200/200 [00:00<00:00, 298.64it/s]\n","Augmenting S: 100%|██████████| 200/200 [00:00<00:00, 681.90it/s]\n","Augmenting G: 100%|██████████| 200/200 [00:00<00:00, 647.28it/s]\n","Augmenting B: 100%|██████████| 200/200 [00:00<00:00, 447.54it/s]\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import albumentations as A\n","from tqdm import tqdm\n","import random\n","\n","# Path to your dataset\n","dataset_path = '/content/datanew'\n","\n","# How many augmented images to add per folder\n","augmented_count = 300\n","\n","# Augmentation pipeline (excluding horizontal flip)\n","augment = A.Compose([\n","    A.Rotate(limit=15, p=0.8),\n","    A.RandomBrightnessContrast(p=0.8),\n","    A.RandomScale(scale_limit=0.1, p=0.8),\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.0, rotate_limit=0, p=0.7),\n","    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","    A.MotionBlur(blur_limit=3, p=0.2)\n","])\n","\n","def augment_and_save_images(class_folder):\n","    images = [img for img in os.listdir(class_folder) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n","    image_paths = [os.path.join(class_folder, img) for img in images]\n","\n","    if len(image_paths) == 0:\n","        return\n","\n","    for i in tqdm(range(augmented_count), desc=f\"Augmenting {os.path.basename(class_folder)}\"):\n","        img_path = random.choice(image_paths)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        augmented = augment(image=image)['image']\n","        output_image = cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)\n","\n","        out_path = os.path.join(class_folder, f\"aug_{i}.jpg\")\n","        cv2.imwrite(out_path, output_image)\n","\n","# Loop through each class folder\n","for class_name in os.listdir(dataset_path):\n","    class_path = os.path.join(dataset_path, class_name)\n","    if os.path.isdir(class_path):\n","        augment_and_save_images(class_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vaqRv9FIlpw","executionInfo":{"status":"ok","timestamp":1744866345131,"user_tz":-330,"elapsed":15250,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"ac3b6d80-ddc4-459b-8d2d-1c06d032c8bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n","<ipython-input-5-c18346793760>:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n","Augmenting W: 100%|██████████| 300/300 [00:00<00:00, 614.86it/s]\n","Augmenting J: 100%|██████████| 300/300 [00:00<00:00, 780.16it/s]\n","Augmenting Q: 100%|██████████| 300/300 [00:00<00:00, 829.37it/s]\n","Augmenting Y: 100%|██████████| 300/300 [00:00<00:00, 806.21it/s]\n","Augmenting N: 100%|██████████| 300/300 [00:00<00:00, 810.76it/s]\n","Augmenting X: 100%|██████████| 300/300 [00:00<00:00, 800.39it/s]\n","Augmenting R: 100%|██████████| 300/300 [00:00<00:00, 776.80it/s]\n","Augmenting M: 100%|██████████| 300/300 [00:00<00:00, 828.07it/s]\n","Augmenting E: 100%|██████████| 300/300 [00:00<00:00, 714.51it/s]\n","Augmenting T: 100%|██████████| 300/300 [00:00<00:00, 536.20it/s]\n","Augmenting P: 100%|██████████| 300/300 [00:00<00:00, 589.46it/s]\n","Augmenting none: 100%|██████████| 300/300 [00:01<00:00, 193.32it/s]\n","Augmenting D: 100%|██████████| 300/300 [00:00<00:00, 814.01it/s]\n","Augmenting F: 100%|██████████| 300/300 [00:00<00:00, 750.11it/s]\n","Augmenting K: 100%|██████████| 300/300 [00:00<00:00, 816.52it/s]\n","Augmenting A: 100%|██████████| 300/300 [00:00<00:00, 809.33it/s]\n","Augmenting Z: 100%|██████████| 300/300 [00:00<00:00, 825.18it/s]\n","Augmenting H: 100%|██████████| 300/300 [00:00<00:00, 742.17it/s]\n","Augmenting S: 100%|██████████| 300/300 [00:00<00:00, 743.73it/s]\n","Augmenting G: 100%|██████████| 300/300 [00:00<00:00, 825.66it/s]\n","Augmenting B: 100%|██████████| 300/300 [00:00<00:00, 788.29it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1891026,"status":"ok","timestamp":1744913495459,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"zYaJmzxKPpcu","outputId":"3d4476cb-6cf1-44c7-8001-8f8102c58964"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://storage.googleapis.com/mediapipe-assets/palm_detection_full.tflite to /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/hand_landmark_full.tflite to /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"]}],"source":["data = gesture_recognizer.Dataset.from_folder(\n","    dirname=dataset_path,\n","    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",")\n","train_data, rest_data = data.split(0.8)\n","validation_data, test_data = rest_data.split(0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08fMv4bBQDPQ","executionInfo":{"status":"ok","timestamp":1744918436428,"user_tz":-330,"elapsed":2193227,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"fbf4cf34-3531-4ef9-ea8d-712cd209a76e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hand_embedding (InputLayer  [(None, 128)]             0         \n"," )                                                               \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 128)               512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_4 (ReLU)              (None, 128)               0         \n","                                                                 \n"," dropout_4 (Dropout)         (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 128)               16512     \n"," 0 (Dense)                                                       \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 128)               512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_5 (ReLU)              (None, 128)               0         \n","                                                                 \n"," dropout_5 (Dropout)         (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 256)               33024     \n"," 1 (Dense)                                                       \n","                                                                 \n"," batch_normalization_6 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_6 (ReLU)              (None, 256)               0         \n","                                                                 \n"," dropout_6 (Dropout)         (None, 256)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 128)               32896     \n"," 2 (Dense)                                                       \n","                                                                 \n"," batch_normalization_7 (Bat  (None, 128)               512       \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_7 (ReLU)              (None, 128)               0         \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 21)                2709      \n"," out (Dense)                                                     \n","                                                                 \n","=================================================================\n","Total params: 87701 (342.58 KB)\n","Trainable params: 86421 (337.58 KB)\n","Non-trainable params: 1280 (5.00 KB)\n","_________________________________________________________________\n","None\n","Resuming from exported_model_new/epoch_models/model-0030\n","Epoch 1/50\n","1652/1652 [==============================] - 42s 23ms/step - loss: 0.1663 - categorical_accuracy: 0.8852 - val_loss: 0.0631 - val_categorical_accuracy: 0.9489 - lr: 0.0010\n","Epoch 2/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1702 - categorical_accuracy: 0.8838 - val_loss: 0.0652 - val_categorical_accuracy: 0.9552 - lr: 9.5000e-04\n","Epoch 3/50\n","1652/1652 [==============================] - 45s 27ms/step - loss: 0.1670 - categorical_accuracy: 0.8870 - val_loss: 0.0609 - val_categorical_accuracy: 0.9564 - lr: 9.0250e-04\n","Epoch 4/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1625 - categorical_accuracy: 0.8889 - val_loss: 0.0598 - val_categorical_accuracy: 0.9580 - lr: 8.5737e-04\n","Epoch 5/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1634 - categorical_accuracy: 0.8877 - val_loss: 0.0573 - val_categorical_accuracy: 0.9580 - lr: 8.1451e-04\n","Epoch 6/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1535 - categorical_accuracy: 0.8927 - val_loss: 0.0588 - val_categorical_accuracy: 0.9598 - lr: 7.7378e-04\n","Epoch 7/50\n","1652/1652 [==============================] - 40s 24ms/step - loss: 0.1516 - categorical_accuracy: 0.8951 - val_loss: 0.0569 - val_categorical_accuracy: 0.9610 - lr: 7.3509e-04\n","Epoch 8/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1542 - categorical_accuracy: 0.8944 - val_loss: 0.0576 - val_categorical_accuracy: 0.9598 - lr: 6.9834e-04\n","Epoch 9/50\n","1652/1652 [==============================] - 38s 23ms/step - loss: 0.1508 - categorical_accuracy: 0.8948 - val_loss: 0.0563 - val_categorical_accuracy: 0.9555 - lr: 6.6342e-04\n","Epoch 10/50\n","1652/1652 [==============================] - 37s 23ms/step - loss: 0.1457 - categorical_accuracy: 0.8950 - val_loss: 0.0538 - val_categorical_accuracy: 0.9595 - lr: 6.3025e-04\n","Epoch 11/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1423 - categorical_accuracy: 0.9013 - val_loss: 0.0520 - val_categorical_accuracy: 0.9601 - lr: 5.9874e-04\n","Epoch 12/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1409 - categorical_accuracy: 0.8975 - val_loss: 0.0541 - val_categorical_accuracy: 0.9616 - lr: 5.6880e-04\n","Epoch 13/50\n","1652/1652 [==============================] - 38s 23ms/step - loss: 0.1392 - categorical_accuracy: 0.9010 - val_loss: 0.0516 - val_categorical_accuracy: 0.9646 - lr: 5.4036e-04\n","Epoch 14/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1332 - categorical_accuracy: 0.9033 - val_loss: 0.0528 - val_categorical_accuracy: 0.9634 - lr: 5.1334e-04\n","Epoch 15/50\n","1652/1652 [==============================] - 44s 26ms/step - loss: 0.1349 - categorical_accuracy: 0.9058 - val_loss: 0.0504 - val_categorical_accuracy: 0.9673 - lr: 4.8767e-04\n","Epoch 16/50\n","1652/1652 [==============================] - 48s 29ms/step - loss: 0.1358 - categorical_accuracy: 0.9037 - val_loss: 0.0531 - val_categorical_accuracy: 0.9613 - lr: 4.6329e-04\n","Epoch 17/50\n","1652/1652 [==============================] - 42s 26ms/step - loss: 0.1271 - categorical_accuracy: 0.9080 - val_loss: 0.0484 - val_categorical_accuracy: 0.9698 - lr: 4.4013e-04\n","Epoch 18/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1300 - categorical_accuracy: 0.9061 - val_loss: 0.0523 - val_categorical_accuracy: 0.9631 - lr: 4.1812e-04\n","Epoch 19/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1276 - categorical_accuracy: 0.9080 - val_loss: 0.0510 - val_categorical_accuracy: 0.9652 - lr: 3.9721e-04\n","Epoch 20/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1248 - categorical_accuracy: 0.9078 - val_loss: 0.0482 - val_categorical_accuracy: 0.9667 - lr: 3.7735e-04\n","Epoch 21/50\n","1652/1652 [==============================] - 39s 23ms/step - loss: 0.1230 - categorical_accuracy: 0.9097 - val_loss: 0.0478 - val_categorical_accuracy: 0.9673 - lr: 3.5849e-04\n","Epoch 22/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1289 - categorical_accuracy: 0.9086 - val_loss: 0.0482 - val_categorical_accuracy: 0.9698 - lr: 3.4056e-04\n","Epoch 23/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1226 - categorical_accuracy: 0.9119 - val_loss: 0.0500 - val_categorical_accuracy: 0.9670 - lr: 3.2353e-04\n","Epoch 24/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1237 - categorical_accuracy: 0.9092 - val_loss: 0.0483 - val_categorical_accuracy: 0.9652 - lr: 3.0736e-04\n","Epoch 25/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1196 - categorical_accuracy: 0.9108 - val_loss: 0.0468 - val_categorical_accuracy: 0.9679 - lr: 2.9199e-04\n","Epoch 26/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1211 - categorical_accuracy: 0.9121 - val_loss: 0.0478 - val_categorical_accuracy: 0.9640 - lr: 2.7739e-04\n","Epoch 27/50\n","1652/1652 [==============================] - 36s 22ms/step - loss: 0.1257 - categorical_accuracy: 0.9098 - val_loss: 0.0483 - val_categorical_accuracy: 0.9658 - lr: 2.6352e-04\n","Epoch 28/50\n","1652/1652 [==============================] - 42s 25ms/step - loss: 0.1197 - categorical_accuracy: 0.9112 - val_loss: 0.0480 - val_categorical_accuracy: 0.9664 - lr: 2.5034e-04\n","Epoch 29/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1194 - categorical_accuracy: 0.9118 - val_loss: 0.0473 - val_categorical_accuracy: 0.9679 - lr: 2.3783e-04\n","Epoch 30/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1171 - categorical_accuracy: 0.9136 - val_loss: 0.0465 - val_categorical_accuracy: 0.9685 - lr: 2.2594e-04\n","Epoch 31/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1173 - categorical_accuracy: 0.9135 - val_loss: 0.0470 - val_categorical_accuracy: 0.9691 - lr: 2.1464e-04\n","Epoch 32/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1167 - categorical_accuracy: 0.9146 - val_loss: 0.0478 - val_categorical_accuracy: 0.9655 - lr: 2.0391e-04\n","Epoch 33/50\n","1652/1652 [==============================] - 36s 22ms/step - loss: 0.1151 - categorical_accuracy: 0.9150 - val_loss: 0.0451 - val_categorical_accuracy: 0.9673 - lr: 1.9371e-04\n","Epoch 34/50\n","1652/1652 [==============================] - 36s 22ms/step - loss: 0.1185 - categorical_accuracy: 0.9145 - val_loss: 0.0458 - val_categorical_accuracy: 0.9667 - lr: 1.8403e-04\n","Epoch 35/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1135 - categorical_accuracy: 0.9143 - val_loss: 0.0463 - val_categorical_accuracy: 0.9691 - lr: 1.7482e-04\n","Epoch 36/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1125 - categorical_accuracy: 0.9177 - val_loss: 0.0456 - val_categorical_accuracy: 0.9664 - lr: 1.6608e-04\n","Epoch 37/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1091 - categorical_accuracy: 0.9179 - val_loss: 0.0457 - val_categorical_accuracy: 0.9676 - lr: 1.5778e-04\n","Epoch 38/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1136 - categorical_accuracy: 0.9160 - val_loss: 0.0450 - val_categorical_accuracy: 0.9691 - lr: 1.4989e-04\n","Epoch 39/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1141 - categorical_accuracy: 0.9150 - val_loss: 0.0443 - val_categorical_accuracy: 0.9704 - lr: 1.4240e-04\n","Epoch 40/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1123 - categorical_accuracy: 0.9156 - val_loss: 0.0462 - val_categorical_accuracy: 0.9676 - lr: 1.3528e-04\n","Epoch 41/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1113 - categorical_accuracy: 0.9173 - val_loss: 0.0460 - val_categorical_accuracy: 0.9667 - lr: 1.2851e-04\n","Epoch 42/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1097 - categorical_accuracy: 0.9184 - val_loss: 0.0454 - val_categorical_accuracy: 0.9667 - lr: 1.2209e-04\n","Epoch 43/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1059 - categorical_accuracy: 0.9196 - val_loss: 0.0449 - val_categorical_accuracy: 0.9685 - lr: 1.1598e-04\n","Epoch 44/50\n","1652/1652 [==============================] - 36s 22ms/step - loss: 0.1087 - categorical_accuracy: 0.9174 - val_loss: 0.0455 - val_categorical_accuracy: 0.9679 - lr: 1.1018e-04\n","Epoch 45/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1086 - categorical_accuracy: 0.9190 - val_loss: 0.0453 - val_categorical_accuracy: 0.9667 - lr: 1.0467e-04\n","Epoch 46/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1073 - categorical_accuracy: 0.9194 - val_loss: 0.0451 - val_categorical_accuracy: 0.9676 - lr: 9.9440e-05\n","Epoch 47/50\n","1652/1652 [==============================] - 41s 25ms/step - loss: 0.1095 - categorical_accuracy: 0.9185 - val_loss: 0.0444 - val_categorical_accuracy: 0.9691 - lr: 9.4468e-05\n","Epoch 48/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1072 - categorical_accuracy: 0.9193 - val_loss: 0.0445 - val_categorical_accuracy: 0.9688 - lr: 8.9745e-05\n","Epoch 49/50\n","1652/1652 [==============================] - 37s 22ms/step - loss: 0.1087 - categorical_accuracy: 0.9183 - val_loss: 0.0449 - val_categorical_accuracy: 0.9682 - lr: 8.5258e-05\n","Epoch 50/50\n","1652/1652 [==============================] - 35s 21ms/step - loss: 0.1067 - categorical_accuracy: 0.9196 - val_loss: 0.0443 - val_categorical_accuracy: 0.9691 - lr: 8.0995e-05\n"]}],"source":["hparams = gesture_recognizer.HParams(export_dir=\"exported_model_new\", batch_size=16, learning_rate = 0.001, lr_decay = 0.95, shuffle = True, epochs = 50)\n","model_options = gesture_recognizer.ModelOptions(dropout_rate = 0.15, layer_widths = [128, 256, 128])\n","options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options,hparams=hparams)\n","model = gesture_recognizer.GestureRecognizer.create(\n","    train_data=train_data,\n","    validation_data=validation_data,\n","    options=options\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23300,"status":"ok","timestamp":1744918513337,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"},"user_tz":-330},"id":"k3YOH65oQIkS","outputId":"af150fc3-b9f5-4dab-f510-736da5cb0961"},"outputs":[{"output_type":"stream","name":"stdout","text":["3306/3306 [==============================] - 23s 3ms/step - loss: 0.0463 - categorical_accuracy: 0.9679\n","Test loss:0.046288978308439255, Test accuracy:0.9679371118545532\n"]}],"source":["loss, acc = model.evaluate(test_data, batch_size=1)\n","print(f\"Test loss:{loss}, Test accuracy:{acc}\")"]},{"cell_type":"code","source":["# Assuming `model` is the trained model using custom architecture\n","import mediapipe as mp\n","\n","# Define the export directory\n","export_dir = \"custom_model_export\"  # Change to your desired export directory\n","\n","# Save the model in the appropriate format (MediaPipe will save this internally)\n","hparams = gesture_recognizer.HParams(export_dir=export_dir, batch_size=16, learning_rate=0.001, lr_decay=0.95, shuffle=True, epochs=30)\n","model_options = gesture_recognizer.ModelOptions(dropout_rate=0.15, layer_widths=[128, 256, 128])\n","options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options, hparams=hparams)\n","\n","# Assuming `train_data` and `validation_data` are defined\n","recognizer_model = gesture_recognizer.GestureRecognizer.create(\n","    train_data=train_data,\n","    validation_data=validation_data,\n","    options=options\n",")\n","\n","# The trained model should now be saved in `custom_model_export/gesture_recognizer.task` (or similar)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCbsry8Ob-LW","executionInfo":{"status":"ok","timestamp":1744874014808,"user_tz":-330,"elapsed":599130,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"8a81f2ce-5e6a-4598-df4c-503d5dd61d2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hand_embedding (InputLayer  [(None, 128)]             0         \n"," )                                                               \n","                                                                 \n"," batch_normalization_12 (Ba  (None, 128)               512       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_12 (ReLU)             (None, 128)               0         \n","                                                                 \n"," dropout_12 (Dropout)        (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 128)               16512     \n"," 0 (Dense)                                                       \n","                                                                 \n"," batch_normalization_13 (Ba  (None, 128)               512       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_13 (ReLU)             (None, 128)               0         \n","                                                                 \n"," dropout_13 (Dropout)        (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 256)               33024     \n"," 1 (Dense)                                                       \n","                                                                 \n"," batch_normalization_14 (Ba  (None, 256)               1024      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_14 (ReLU)             (None, 256)               0         \n","                                                                 \n"," dropout_14 (Dropout)        (None, 256)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 128)               32896     \n"," 2 (Dense)                                                       \n","                                                                 \n"," batch_normalization_15 (Ba  (None, 128)               512       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_15 (ReLU)             (None, 128)               0         \n","                                                                 \n"," dropout_15 (Dropout)        (None, 128)               0         \n","                                                                 \n"," custom_gesture_recognizer_  (None, 21)                2709      \n"," out (Dense)                                                     \n","                                                                 \n","=================================================================\n","Total params: 87701 (342.58 KB)\n","Trainable params: 86421 (337.58 KB)\n","Non-trainable params: 1280 (5.00 KB)\n","_________________________________________________________________\n","None\n","Epoch 1/30\n","1301/1301 [==============================] - 18s 13ms/step - loss: 0.3318 - categorical_accuracy: 0.8409 - val_loss: 0.0356 - val_categorical_accuracy: 0.9758 - lr: 0.0010\n","Epoch 2/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.1324 - categorical_accuracy: 0.9183 - val_loss: 0.0265 - val_categorical_accuracy: 0.9831 - lr: 9.5000e-04\n","Epoch 3/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.1059 - categorical_accuracy: 0.9293 - val_loss: 0.0201 - val_categorical_accuracy: 0.9854 - lr: 9.0250e-04\n","Epoch 4/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0883 - categorical_accuracy: 0.9421 - val_loss: 0.0177 - val_categorical_accuracy: 0.9866 - lr: 8.5737e-04\n","Epoch 5/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.0810 - categorical_accuracy: 0.9455 - val_loss: 0.0151 - val_categorical_accuracy: 0.9904 - lr: 8.1451e-04\n","Epoch 6/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.0713 - categorical_accuracy: 0.9493 - val_loss: 0.0103 - val_categorical_accuracy: 0.9919 - lr: 7.7378e-04\n","Epoch 7/30\n","1301/1301 [==============================] - 22s 17ms/step - loss: 0.0624 - categorical_accuracy: 0.9545 - val_loss: 0.0100 - val_categorical_accuracy: 0.9912 - lr: 7.3509e-04\n","Epoch 8/30\n","1301/1301 [==============================] - 20s 15ms/step - loss: 0.0604 - categorical_accuracy: 0.9544 - val_loss: 0.0089 - val_categorical_accuracy: 0.9962 - lr: 6.9834e-04\n","Epoch 9/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0579 - categorical_accuracy: 0.9571 - val_loss: 0.0075 - val_categorical_accuracy: 0.9962 - lr: 6.6342e-04\n","Epoch 10/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0527 - categorical_accuracy: 0.9611 - val_loss: 0.0060 - val_categorical_accuracy: 0.9954 - lr: 6.3025e-04\n","Epoch 11/30\n","1301/1301 [==============================] - 20s 16ms/step - loss: 0.0568 - categorical_accuracy: 0.9571 - val_loss: 0.0060 - val_categorical_accuracy: 0.9962 - lr: 5.9874e-04\n","Epoch 12/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0517 - categorical_accuracy: 0.9628 - val_loss: 0.0055 - val_categorical_accuracy: 0.9962 - lr: 5.6880e-04\n","Epoch 13/30\n","1301/1301 [==============================] - 20s 16ms/step - loss: 0.0473 - categorical_accuracy: 0.9645 - val_loss: 0.0063 - val_categorical_accuracy: 0.9942 - lr: 5.4036e-04\n","Epoch 14/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0448 - categorical_accuracy: 0.9661 - val_loss: 0.0053 - val_categorical_accuracy: 0.9954 - lr: 5.1334e-04\n","Epoch 15/30\n","1301/1301 [==============================] - 20s 16ms/step - loss: 0.0425 - categorical_accuracy: 0.9666 - val_loss: 0.0054 - val_categorical_accuracy: 0.9958 - lr: 4.8767e-04\n","Epoch 16/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0419 - categorical_accuracy: 0.9668 - val_loss: 0.0062 - val_categorical_accuracy: 0.9946 - lr: 4.6329e-04\n","Epoch 17/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0420 - categorical_accuracy: 0.9669 - val_loss: 0.0049 - val_categorical_accuracy: 0.9973 - lr: 4.4013e-04\n","Epoch 18/30\n","1301/1301 [==============================] - 18s 14ms/step - loss: 0.0393 - categorical_accuracy: 0.9694 - val_loss: 0.0044 - val_categorical_accuracy: 0.9950 - lr: 4.1812e-04\n","Epoch 19/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0390 - categorical_accuracy: 0.9688 - val_loss: 0.0049 - val_categorical_accuracy: 0.9950 - lr: 3.9721e-04\n","Epoch 20/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.0356 - categorical_accuracy: 0.9725 - val_loss: 0.0046 - val_categorical_accuracy: 0.9958 - lr: 3.7735e-04\n","Epoch 21/30\n","1301/1301 [==============================] - 21s 16ms/step - loss: 0.0389 - categorical_accuracy: 0.9696 - val_loss: 0.0035 - val_categorical_accuracy: 0.9965 - lr: 3.5849e-04\n","Epoch 22/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0351 - categorical_accuracy: 0.9720 - val_loss: 0.0049 - val_categorical_accuracy: 0.9965 - lr: 3.4056e-04\n","Epoch 23/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0360 - categorical_accuracy: 0.9722 - val_loss: 0.0033 - val_categorical_accuracy: 0.9977 - lr: 3.2353e-04\n","Epoch 24/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.0332 - categorical_accuracy: 0.9712 - val_loss: 0.0034 - val_categorical_accuracy: 0.9973 - lr: 3.0736e-04\n","Epoch 25/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0320 - categorical_accuracy: 0.9741 - val_loss: 0.0031 - val_categorical_accuracy: 0.9958 - lr: 2.9199e-04\n","Epoch 26/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0348 - categorical_accuracy: 0.9734 - val_loss: 0.0034 - val_categorical_accuracy: 0.9950 - lr: 2.7739e-04\n","Epoch 27/30\n","1301/1301 [==============================] - 17s 13ms/step - loss: 0.0336 - categorical_accuracy: 0.9719 - val_loss: 0.0032 - val_categorical_accuracy: 0.9962 - lr: 2.6352e-04\n","Epoch 28/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0315 - categorical_accuracy: 0.9723 - val_loss: 0.0034 - val_categorical_accuracy: 0.9954 - lr: 2.5034e-04\n","Epoch 29/30\n","1301/1301 [==============================] - 16s 12ms/step - loss: 0.0293 - categorical_accuracy: 0.9750 - val_loss: 0.0037 - val_categorical_accuracy: 0.9958 - lr: 2.3783e-04\n","Epoch 30/30\n","1301/1301 [==============================] - 16s 13ms/step - loss: 0.0285 - categorical_accuracy: 0.9751 - val_loss: 0.0036 - val_categorical_accuracy: 0.9958 - lr: 2.2594e-04\n"]}]},{"cell_type":"code","source":["files.download(\"gesture_model.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"OVA8l4AxcIHT","executionInfo":{"status":"ok","timestamp":1744871398478,"user_tz":-330,"elapsed":17,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"c10c102b-5f87-4e8b-ae15-1f5171623b87"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9c2c687e-cfef-4a8c-8695-aa5b77353d09\", \"gesture_model.h5\", 1130032)"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Y7L3UeCQTId"},"outputs":[],"source":["model.export_model()\n","!ls exported_model"]},{"cell_type":"code","source":["import os\n","\n","def list_files(startpath):\n","    for root, dirs, files in os.walk(startpath):\n","        level = root.replace(startpath, '').count(os.sep)\n","        indent = ' ' * 4 * level\n","        print(f\"{indent}{os.path.basename(root)}/\")\n","        subindent = ' ' * 4 * (level + 1)\n","        for f in files:\n","            print(f\"{subindent}{f}\")\n","\n","# Make sure this path is correct in your Colab environment\n","list_files(\"exported_model_new\")\n"],"metadata":{"id":"4zV4IStwdrCu","executionInfo":{"status":"ok","timestamp":1744874636359,"user_tz":-330,"elapsed":13,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c2c080f-de22-40a1-facc-85cf90e7e9ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["exported_model_new/\n","    checkpoint\n","    best_model_weights.index\n","    best_model_weights.data-00000-of-00001\n","    epoch_models/\n","        model-0026.index\n","        model-0002.data-00000-of-00001\n","        model-0025.index\n","        checkpoint\n","        model-0014.index\n","        model-0004.data-00000-of-00001\n","        model-0009.index\n","        model-0005.index\n","        model-0007.data-00000-of-00001\n","        model-0023.data-00000-of-00001\n","        model-0011.index\n","        model-0021.data-00000-of-00001\n","        model-0003.index\n","        model-0027.data-00000-of-00001\n","        model-0011.data-00000-of-00001\n","        model-0006.data-00000-of-00001\n","        model-0009.data-00000-of-00001\n","        model-0029.data-00000-of-00001\n","        model-0013.data-00000-of-00001\n","        model-0016.index\n","        model-0007.index\n","        model-0010.data-00000-of-00001\n","        model-0019.data-00000-of-00001\n","        model-0030.index\n","        model-0013.index\n","        model-0004.index\n","        model-0024.index\n","        model-0008.data-00000-of-00001\n","        model-0030.data-00000-of-00001\n","        model-0001.index\n","        model-0020.index\n","        model-0014.data-00000-of-00001\n","        model-0022.index\n","        model-0005.data-00000-of-00001\n","        model-0028.index\n","        model-0001.data-00000-of-00001\n","        model-0006.index\n","        model-0017.index\n","        model-0016.data-00000-of-00001\n","        model-0015.data-00000-of-00001\n","        model-0022.data-00000-of-00001\n","        model-0010.index\n","        model-0027.index\n","        model-0025.data-00000-of-00001\n","        model-0023.index\n","        model-0012.index\n","        model-0021.index\n","        model-0029.index\n","        model-0018.index\n","        model-0012.data-00000-of-00001\n","        model-0019.index\n","        model-0028.data-00000-of-00001\n","        model-0024.data-00000-of-00001\n","        model-0003.data-00000-of-00001\n","        model-0018.data-00000-of-00001\n","        model-0015.index\n","        model-0008.index\n","        model-0002.index\n","        model-0020.data-00000-of-00001\n","        model-0026.data-00000-of-00001\n","        model-0017.data-00000-of-00001\n","    logs/\n","        train/\n","            events.out.tfevents.1744870362.ecdaf64f3541.617.8.v2\n","        validation/\n","            events.out.tfevents.1744870373.ecdaf64f3541.617.9.v2\n"]}]},{"cell_type":"code","source":["model.export_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQSc3wJRpJOq","executionInfo":{"status":"ok","timestamp":1744918531638,"user_tz":-330,"elapsed":2865,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"190b3a21-54c0-46d8-c591-436e4d47e119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n","Using existing files at /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/exported_model_new/gesture_recognizer.task\")  # or the full path if it's in a folder\n"],"metadata":{"id":"ZfSNUFjFd1BQ","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1744918536155,"user_tz":-330,"elapsed":13,"user":{"displayName":"Tahareen Anjum","userId":"14121897377679081709"}},"outputId":"574a56b5-9353-4fb1-a23c-803eb5e9b0cb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e54c4f5f-cc8b-41fe-a4fb-9e40f379da62\", \"gesture_recognizer.task\", 8801127)"]},"metadata":{}}]},{"cell_type":"markdown","source":["A code that just detects hands with two models switching\n"],"metadata":{"id":"ZmE3uLUB-XF_"}},{"cell_type":"code","source":[],"metadata":{"id":"wr0R1SCDUdkl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["code that takes letters many times depending on the duration of the blink"],"metadata":{"id":"Bq85fo11-IdJ"}},{"cell_type":"code","source":[],"metadata":{"id":"RPRZQS_kCHzM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["code before adding text to speech api"],"metadata":{"id":"dYy0YPw5-z7M"}},{"cell_type":"code","source":[],"metadata":{"id":"ASc-x209-ynG"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOp1C/kAIYo4OXaSsUjE7xW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}